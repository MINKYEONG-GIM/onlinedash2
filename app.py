import streamlit as st
import pandas as pd
from io import BytesIO
import unicodedata



st.set_page_config(page_title="ë¸Œëœë“œ ìƒí’ˆ íë¦„ ëŒ€ì‹œë³´ë“œ", layout="wide")

# ----------------------------
# Google Sheets ì—°ë™
# ----------------------------
def get_gsheet_client(credentials_dict):
    if credentials_dict is None:
        return None
    import gspread
    from google.oauth2.service_account import Credentials
    # ìŠ¤í”„ë ˆë“œì‹œíŠ¸/ì›Œí¬ì‹œíŠ¸ë¥¼ "ìƒì„±"ê¹Œì§€ í•˜ë ¤ë©´ readonly ê¶Œí•œìœ¼ë¡œëŠ” ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.
    # ì½ê¸°ë§Œ í•´ë„ ì•„ë˜ scopeëŠ” ë™ì‘í•˜ë©°, ìƒì„±/ì¶”ê°€ ì‹œíŠ¸ ë“±ë„ ì§€ì›í•©ë‹ˆë‹¤.
    scope = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive",
    ]
    creds = Credentials.from_service_account_info(
        credentials_dict, scopes=scope
    )
    return gspread.authorize(creds)


def _normalize_spreadsheet_id(spreadsheet_id_or_url):
    """ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID ë˜ëŠ” URLì„ ë°›ì•„ IDë¡œ ì •ê·œí™”."""
    import re

    if spreadsheet_id_or_url is None:
        return ""
    s = str(spreadsheet_id_or_url).strip()
    if not s:
        return ""

    # URL: https://docs.google.com/spreadsheets/d/<ID>/edit...
    m = re.search(r"/spreadsheets/d/([a-zA-Z0-9-_]+)", s)
    if m:
        return m.group(1)

    # ê³µìœ  ë§í¬ì— key= ë¡œ ë“¤ì–´ì˜¤ëŠ” ì¼€ì´ìŠ¤
    m = re.search(r"(?:^|[?&])key=([a-zA-Z0-9-_]+)", s)
    if m:
        return m.group(1)

    return s


def open_or_create_spreadsheet(client, spreadsheet_id=None, spreadsheet_title=None, create_if_missing=False):
    """IDê°€ ìˆìœ¼ë©´ open_by_key, ì—†ìœ¼ë©´ titleë¡œ open(ì˜µì…˜ìœ¼ë¡œ create)."""
    import gspread

    sid = _normalize_spreadsheet_id(spreadsheet_id)
    if sid:
        return client.open_by_key(sid)

    title = (spreadsheet_title or "").strip() if spreadsheet_title else ""
    if not title:
        raise ValueError("ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID/URL ë˜ëŠ” ì œëª©(spreadsheet_title)ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    try:
        return client.open(title)
    except gspread.exceptions.SpreadsheetNotFound:
        if not create_if_missing:
            raise
        return client.create(title)


@st.cache_data(ttl=90)
def _cached_load_sheet(spreadsheet_id: str, sheet_name: str, header_row: int):
    """ì‹œíŠ¸ ì½ê¸° ê²°ê³¼ë¥¼ 90ì´ˆ ìºì‹œí•˜ì—¬ API 429(Quota exceeded) ì™„í™”."""
    if not spreadsheet_id or not str(spreadsheet_id).strip():
        return None
    try:
        if "gcp_service_account" in st.secrets:
            creds_dict = dict(st.secrets["gcp_service_account"])
        elif "google_service_account" in st.secrets:
            creds_dict = dict(st.secrets["google_service_account"])
        else:
            return None
    except Exception:
        return None
    client = get_gsheet_client(creds_dict)
    if client is None:
        return None
    return load_sheet_as_dataframe(
        client,
        spreadsheet_id,
        sheet_name=sheet_name or None,
        header_row=header_row,
    )


def load_sheet_as_dataframe(
    client,
    spreadsheet_id=None,
    sheet_name=None,
    header_row=0,
    spreadsheet_title=None,
    create_spreadsheet_if_missing=False,
    create_worksheet_if_missing=False,
):
    """header_row: 0 = ì²« ë²ˆì§¸ í–‰ì´ í—¤ë”(ê¸°ë³¸), 1 = ë‘ ë²ˆì§¸ í–‰ì´ í—¤ë” ë“±"""
    try:
        spreadsheet = open_or_create_spreadsheet(
            client,
            spreadsheet_id=spreadsheet_id,
            spreadsheet_title=spreadsheet_title,
            create_if_missing=create_spreadsheet_if_missing,
        )

        # ì›Œí¬ì‹œíŠ¸ëŠ” ë°˜ë“œì‹œ "ìŠ¤í”„ë ˆë“œì‹œíŠ¸ë¥¼ ì—° ë’¤"ì— ê°€ì ¸ì˜µë‹ˆë‹¤.
        if sheet_name and str(sheet_name).strip():
            try:
                worksheet = spreadsheet.worksheet(str(sheet_name).strip())
            except Exception as e:
                # ì—†ëŠ” ì›Œí¬ì‹œíŠ¸ë¥¼ ìš”ì²­í•œ ê²½ìš°(ì˜µì…˜) ìƒì„±
                if create_worksheet_if_missing:
                    worksheet = spreadsheet.add_worksheet(title=str(sheet_name).strip(), rows=1000, cols=26)
                else:
                    raise e
        else:
            worksheet = spreadsheet.sheet1

        rows = worksheet.get_all_values()
        if not rows:
            return pd.DataFrame()
        # ìë™ í—¤ë” ê°ì§€: 1í–‰ì— 'ë¦¬í„°ì¹­'ì´ ì—†ìœ¼ë©´ 2í–‰Â·3í–‰ ì‹œë„ (ì‹¤ì œ ë¨¸ë¦¿ê¸€ì´ 2í–‰ì¸ ì‹œíŠ¸ ëŒ€ì‘)
        if header_row == -1:
            header_row = 0
            for try_row in range(min(3, len(rows))):
                try_headers = [str(h).strip() for h in rows[try_row]]
                if any("ë¦¬í„°ì¹­" in str(h) for h in try_headers):
                    header_row = try_row
                    break
        if len(rows) <= header_row:
            return pd.DataFrame()
        headers = [str(h).strip() for h in rows[header_row]]
        data_rows = rows[header_row + 1:]
        return pd.DataFrame(data_rows, columns=headers)
    except Exception as e:
        st.error(f"ì‹œíŠ¸ ì½ê¸° ì˜¤ë¥˜: {e}")
        return None

# ìŠ¤íƒ€ì¼ì½”ë“œ ì• 2ìë¦¬ â†’ ë¸Œëœë“œ í•œê¸€ëª…
BRAND_CODE_MAP = {
    "sp": "ìŠ¤íŒŒì˜¤",
    "rm": "ë¡œì— ",
    "mi": "ë¯¸ì˜",
    "wh": "í›„ì•„ìœ ",
    "nb": "ë‰´ë°œë€ìŠ¤",
    "eb": "ì—ë¸”ë¦°",
    "hp": "ìŠˆíœ",
    "cv": "í´ë¼ë¹„ìŠ¤",
    "nk": "ë‰´ë°œë€ìŠ¤í‚¤ì¦ˆ",
}
# ë¸Œëœë“œë³„ ì´¬ì˜Â·ë“±ë¡ ì—¬ë¶€ ì‹œíŠ¸ (í•´ë‹¹ ì‹œíŠ¸ì—ì„œë§Œ ì½ì–´ì„œ merge)
BRAND_TO_SHEET = {
    "ìŠ¤íŒŒì˜¤": "SP",
    "ë¯¸ì˜": "MI",
    "í´ë¼ë¹„ìŠ¤": "CV",
    "ë¡œì— ": "RM",
    "í›„ì•„ìœ ": "WH",
    "ìŠˆíœ": "HP",  
    "ì—ë¸”ë¦°": "EB", 
    "ë‰´ë°œë€ìŠ¤í‚¤ì¦ˆ": "NK"
}

def _normalize_style_code_for_merge(val):
    """merge ì‹œ ë¸Œëœë“œ ì‹œíŠ¸Â·BASE ì‹œíŠ¸ ê°„ ìŠ¤íƒ€ì¼ì½”ë“œ ë§¤ì¹­ì„ ìœ„í•´ ë™ì¼ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™” (ê³µë°± ì œê±°, nan ì²˜ë¦¬)"""
    if pd.isna(val):
        return ""
    s = str(val).strip()
    if not s or s.lower() == "nan":
        return ""
    return "".join(s.split())


def brand_from_style_code(style_code):
    """ìŠ¤íƒ€ì¼ì½”ë“œ ì• 2ìë¦¬ë¡œ ë¸Œëœë“œëª… ë°˜í™˜ (ì†Œë¬¸ìë¡œ ë§¤í•‘)"""
    if pd.isna(style_code) or not str(style_code).strip():
        return ""
    code = str(style_code).strip()[:2].lower()
    return BRAND_CODE_MAP.get(code, code.upper())

# ìŠ¤íƒ€ì¼ì½”ë“œ 5ë²ˆì§¸ ìë¦¬ â†’ ì—°ë„, 6ë²ˆì§¸ ìë¦¬ â†’ ì‹œì¦Œ. ì˜ˆ: sp23g1fh28 â†’ 5ë²ˆì§¸ G=2026ë…„, 6ë²ˆì§¸ 1=1ì‹œì¦Œ â†’ 20261 ì‹œì¦Œ ìƒí’ˆ
STYLE_CODE_SEASON_TO_YEAR = {
    "G": "2026",
    "F": "2025",
    "H": "2027",
}

def year_from_style_code(style_code):
    """ìŠ¤íƒ€ì¼ì½”ë“œ 5ë²ˆì§¸ ìë¦¬ê°€ ì—°ë„ê°’ì´ë©´ í•´ë‹¹ ì—°ë„ ë°˜í™˜ (ì˜ˆ: G â†’ 2026). ë§¤í•‘ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´."""
    if pd.isna(style_code) or not str(style_code).strip():
        return ""
    s = str(style_code).strip()
    if len(s) < 5:
        return ""
    year_char = s[4].upper()
    return STYLE_CODE_SEASON_TO_YEAR.get(year_char, "")


def year_season_from_style_code(style_code):
    """ìŠ¤íƒ€ì¼ì½”ë“œ 5ë²ˆì§¸(ì—°ë„)Â·6ë²ˆì§¸(ì‹œì¦Œ) ìë¦¬ë¡œ '20261' í˜•íƒœ ë°˜í™˜. í‘œì‹œìš© '20261 ì‹œì¦Œ ìƒí’ˆ'ë„ ë°˜í™˜."""
    if pd.isna(style_code) or not str(style_code).strip():
        return "", ""
    s = str(style_code).strip()
    if len(s) < 6:
        return "", ""
    y = year_from_style_code(style_code)
    if not y:
        return "", ""
    season_digit = s[5]
    if not season_digit.isdigit():
        return "", ""
    ys = y + season_digit
    return ys, f"{ys} ì‹œì¦Œ ìƒí’ˆ"

# ì‹œíŠ¸ ì»¬ëŸ¼ëª… â†’ ì•± í•„ìˆ˜ ì»¬ëŸ¼ëª… ë§¤í•‘ (í•œê¸€/ë‹¤ë¥¸ í‘œê¸° ì§€ì›)
COLUMN_ALIASES = {
    "ë¸Œëœë“œ": "brand",
    "ì—°ë„ì‹œì¦Œ": "yearSeason",
    "ì—°ë„Â·ì‹œì¦Œ": "yearSeason",
    "ì—°ë„ ì‹œì¦Œ": "yearSeason",
    "ì‹œì¦Œ(Now)": "yearSeason",
    "ìŠ¤íƒ€ì¼ì½”ë“œ": "styleCode",
    "ìŠ¤íƒ€ì¼ ì½”ë“œ": "styleCode",
    "ìŠ¤íƒ€ì¼ì½”ë“œ(Now)": "styleCode",
    "ìƒí’ˆëª…": "productName",
    "ì»¬ëŸ¬ì½”ë“œ": "colorCode",
    "ìƒ‰ìƒì½”ë“œ": "colorCode",
    "ì»¬ëŸ¬ ì½”ë“œ": "colorCode",
    "ì»¬ëŸ¬ëª…": "colorName",
    "ìƒ‰ìƒ": "colorName",
    "ì»¬ëŸ¬ ëª…": "colorName",
    "ì¹¼ë¼(Now)": "colorName",
    "ì‚¬ì´ì¦ˆì½”ë“œ": "sizeCode",
    "ì‚¬ì´ì¦ˆ ì½”ë“œ": "sizeCode",
    "ì…ê³ ìˆ˜ëŸ‰": "inboundQty",
    "ì¶œê³ ìˆ˜ëŸ‰": "outboundQty",
    "ì¬ê³ ìˆ˜ëŸ‰": "stockQty",
    "íŒë§¤ìˆ˜ëŸ‰": "salesQty",
    "ëˆ„ì ì…ê³ ëŸ‰(ë¬¼ë¥˜+ì…ê³ ì¡°ì •+ë¸Œëœë“œê°„)": "inboundQty",
    "ì¶œê³ ëŸ‰[ì¶œê³ -ë°˜í’ˆ](ë§¤ì¥+ê³ ê°+ìƒ˜í”Œ+ë¸Œëœë“œê°„)": "outboundQty",
    "ëˆ„ì  íŒë§¤ëŸ‰": "salesQty",
    "íŒë§¤ì¬ê³ ëŸ‰(ì…ê³ ëŸ‰-ëˆ„íŒëŸ‰)": "stockQty",
    "ë¦¬í„°ì¹­ ì™„ë£Œì¼": "isShot",
    "ë¦¬í„°ì¹­ì™„ë£Œì¼": "isShot",
    "ì—…ë¡œë“œì™„ë£Œì¼": "isShot",
    "ê³µí™ˆë“±ë¡ì¼": "isRegistered",
    "ê³µí™ˆ ë“±ë¡ì¼": "isRegistered",
}

def ensure_year_season_from_columns(df):
    """ë…„ë„(Now) + ì‹œì¦Œ(Now) â†’ yearSeason ì¡°í•©"""
    if "yearSeason" in df.columns:
        return df
    if "ë…„ë„(Now)" in df.columns and "ì‹œì¦Œ(Now)" in df.columns:
        df = df.copy()
        df["yearSeason"] = df["ë…„ë„(Now)"].astype(str) + df["ì‹œì¦Œ(Now)"].astype(str)
    return df

def apply_column_aliases(df):
    """ì»¬ëŸ¼ëª… ì•ë’¤ ê³µë°± ì œê±° í›„ ì•Œë ¤ì§„ ë³„ì¹­ìœ¼ë¡œ ë§¤í•‘"""
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    df = ensure_year_season_from_columns(df)
    rename = {}
    for col in list(df.columns):
        if col in COLUMN_ALIASES:
            target = COLUMN_ALIASES[col]
            # ì´ë¯¸ ìˆëŠ” ì»¬ëŸ¼ìœ¼ë¡œ ë®ì–´ì“°ì§€ ì•ŠìŒ (ì˜ˆ: yearSeasonì€ ë…„ë„+ì‹œì¦Œìœ¼ë¡œ ì´ë¯¸ ì±„ì›€)
            if target not in df.columns or col == target:
                rename[col] = target
    return df.rename(columns=rename) if rename else df

def fill_missing_required_columns(df, required_columns):
    """ì—†ëŠ” í•„ìˆ˜ ì»¬ëŸ¼ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ì›€ (ì‹œíŠ¸ êµ¬ì¡°ê°€ ë‹¤ë¥¼ ë•Œ ëŒ€ì‹œë³´ë“œë§Œ ë™ì‘í•˜ë„ë¡)"""
    df = df.copy()
    for col in required_columns:
        if col not in df.columns:
            if col in ("isShot", "isRegistered", "isOnSale"):
                df[col] = 0
            elif col in ("inboundQty", "outboundQty", "stockQty", "salesQty"):
                df[col] = 0
            else:
                df[col] = ""
    return df

# ----------------------------
# ìƒíƒœ íŒì • ë¡œì§
# ----------------------------
def get_verdict(inbound, outbound, is_shot, is_registered, is_on_sale):
    if inbound > 0 and outbound == 0:
        return "ì…ê³ "
    if outbound > 0 and is_shot == 0:
        return "ì¶œê³ "
    if is_shot == 1 and is_registered == 0:
        return "ì´¬ì˜"
    if is_registered == 1 and is_on_sale == 0:
        return "ë“±ë¡"
    if is_on_sale == 1:
        return "íŒë§¤ê°œì‹œ"
    return "ëŒ€ê¸°"

# ----------------------------
# ì´¬ì˜ ì™„ë£Œ íŒì •: ë¦¬í„°ì¹­ì™„ë£Œì¼Â·ì—…ë¡œë“œì™„ë£Œì¼ ë“± ë‚ ì§œ ì»¬ëŸ¼
# ----------------------------
# ê·œì¹™: "ë¦¬í„°ì¹­ì™„ë£Œì¼" ë˜ëŠ” "ì—…ë¡œë“œì™„ë£Œì¼" ì—´ì— ë‚ ì§œ ê°’ì´ ìˆìœ¼ë©´ ê·¸ í–‰ì€ ì´¬ì˜ O. (í´ë¼ë¹„ìŠ¤ëŠ” ì—…ë¡œë“œì™„ë£Œì¼ ì‚¬ìš©)

def _normalize_col_name(name):
    """ì»¬ëŸ¼ëª… ë¹„êµìš©: ì•ë’¤ ê³µë°±Â·ì œì–´ë¬¸ì ì œê±°, ìœ ë‹ˆì½”ë“œ ì •ê·œí™”, ê³µë°± í†µì¼."""
    if name is None or not isinstance(name, str):
        return ""
    try:
        s = unicodedata.normalize("NFKC", str(name))
    except Exception:
        s = str(name)
    s = s.strip()
    s = "".join(c for c in s if ord(c) >= 32 or c in "\t\n\r")
    return s.replace(" ", "").replace("\u3000", "")

def _find_photo_date_column(df, preferred_name=None):
    """ì´¬ì˜ ì™„ë£Œë¥¼ íŒì •í•  ë‚ ì§œ ì»¬ëŸ¼. ë¦¬í„°ì¹­ì™„ë£Œì¼Â·ì—…ë¡œë“œì™„ë£Œì¼ ìš°ì„ , ì—†ìœ¼ë©´ ì´¬ì˜ì¼ì/í¬í† ì´¬ì˜ì¼ ë“±."""
    # 0ìˆœìœ„: Secretsì— ì§€ì •ëœ ì»¬ëŸ¼ëª…ì´ ìˆìœ¼ë©´ ì •í™•íˆ ê·¸ ì»¬ëŸ¼ ì‚¬ìš©
    if preferred_name and str(preferred_name).strip():
        name = str(preferred_name).strip()
        for c in df.columns:
            if str(c).strip() == name:
                return c
        name_norm = _normalize_col_name(name)
        for c in df.columns:
            if _normalize_col_name(c) == name_norm:
                return c
    # 1ìˆœìœ„: ì´ë¦„ì— "ë¦¬í„°ì¹­"ì´ í¬í•¨ëœ ì»¬ëŸ¼ (ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ë¬´ê´€, ê°€ì¥ ê´€ëŒ€í•˜ê²Œ)
    for c in df.columns:
        raw = str(c)
        if "ë¦¬í„°ì¹­" in raw or "retouch" in raw.lower():
            return c
    # 2ìˆœìœ„: ì—…ë¡œë“œì™„ë£Œì¼ (í´ë¼ë¹„ìŠ¤ ë“± í•´ë‹¹ ì‹œíŠ¸ì—ì„œ ì‚¬ìš©)
    for c in df.columns:
        raw = str(c)
        if "ì—…ë¡œë“œì™„ë£Œì¼" in raw or _normalize_col_name(c) == "ì—…ë¡œë“œì™„ë£Œì¼":
            return c
    # 3ìˆœìœ„: ë¨¸ë¦¿ê¸€ "ë¦¬í„°ì¹­ì™„ë£Œì¼" ì •í™•íˆ (ê³µë°±/ì œì–´ë¬¸ìë§Œ ì •ê·œí™”)
    for c in df.columns:
        if _normalize_col_name(c) == "ë¦¬í„°ì¹­ì™„ë£Œì¼":
            return c
    # 4ìˆœìœ„: ë¦¬í„°ì¹­ ê´€ë ¨ (ì •ê·œí™” í›„ í¬í•¨ ì—¬ë¶€)
    for c in df.columns:
        s_nospace = _normalize_col_name(c)
        if "ë¦¬í„°ì¹­" in s_nospace:
            return c
    # 5ìˆœìœ„: ì´¬ì˜ì¼ì, í¬í† ì´¬ì˜ì¼, ë³´ì •ì™„ë£Œì¼ ë“±
    for c in df.columns:
        s = str(c).strip()
        s_nospace = _normalize_col_name(c)
        s_lower = s.lower()
        if (
            "í¬í† ì´¬ì˜" in s_nospace
            or "ì´¬ì˜ì¼" in s_nospace
            or "ì´¬ì˜ì¼ì" in s_nospace
            or "ë³´ì •ì™„ë£Œ" in s_nospace
            or s in ("photoShotDate", "shotDate", "retouchDoneDate", "retouch_date", "ì´¬ì˜ì¼ì", "ì´¬ì˜ ì¼ì")
        ):
            return c
    # 6ìˆœìœ„: 'OOì™„ë£Œì¼' í˜•íƒœ ì¤‘ ë“±ë¡/íŒë§¤ ì œì™¸
    for c in df.columns:
        s_nospace = _normalize_col_name(c)
        if "ì™„ë£Œì¼" in s_nospace and "ë“±ë¡" not in s_nospace and "íŒë§¤" not in s_nospace:
            return c
    return None


def _find_registration_date_column(df):
    """ë“±ë¡ ì—¬ë¶€ íŒì •ìš© ë‚ ì§œ ì»¬ëŸ¼. ê³µí™ˆë“±ë¡ì¼ ìš°ì„ ."""
    for c in df.columns:
        raw = str(c).strip()
        n = _normalize_col_name(c)
        if "ê³µí™ˆë“±ë¡" in n or "ê³µí™ˆ ë“±ë¡" in n or "ê³µí™ˆë“±ë¡ì¼" in n:
            return c
    return None


def _parse_date_series(ser):
    """ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ íŒŒì‹± (ë¬¸ìì—´, Excel/êµ¬ê¸€ ì‹œíŠ¸ ì¼ë ¨ë²ˆí˜¸ ë“±). ê³µë°±/í˜•ì‹ ì°¨ì´ ê´€ëŒ€í•˜ê²Œ ì²˜ë¦¬."""
    out = pd.to_datetime(ser, errors="coerce")
    # íŒŒì‹± ì‹¤íŒ¨í•œ ì…€: ì•ë’¤ ê³µë°± ì œê±° í›„ ì¬ì‹œë„
    still_na = out.isna()
    if still_na.any():
        try:
            cleaned = ser.astype(str).str.strip()
            out2 = pd.to_datetime(cleaned, errors="coerce")
            out = out.fillna(out2)
        except Exception:
            pass
    # "2025. 1. 15"ì²˜ëŸ¼ ì  ì•ë’¤ ê³µë°± ì œê±° í›„ ì¬ì‹œë„
    still_na = out.isna()
    if still_na.any():
        try:
            s = ser.astype(str).str.strip()
            s = s.str.replace(r"\s*\.\s*", ".", regex=True).str.replace(r"\s*-\s*", "-", regex=True)
            out3 = pd.to_datetime(s, errors="coerce")
            out = out.fillna(out3)
        except Exception:
            pass
    # êµ¬ê¸€ ì‹œíŠ¸/ì—‘ì…€ ë‚ ì§œ ì¼ë ¨ë²ˆí˜¸(ë¬¸ìì—´ "45324" ë“±)
    if out.isna().any():
        numeric = pd.to_numeric(ser, errors="coerce")
        valid_num = numeric.notna() & (numeric > 10000) & (numeric < 1000000)
        if valid_num.any():
            fixed = pd.to_datetime(numeric[valid_num], unit="D", origin="1899-12-30")
            out = out.fillna(fixed)
    return out

def _looks_like_date_value(val):
    """ì…€ ê°’ì´ ë‚ ì§œì²˜ëŸ¼ ë³´ì´ë©´ True (íŒŒì‹± ì‹¤íŒ¨í•´ë„ 'ê°’ ìˆìŒ'ìœ¼ë¡œ ì´¬ì˜ ì™„ë£Œ ì²˜ë¦¬ìš©)."""
    if val is None or (isinstance(val, float) and pd.isna(val)):
        return False
    s = str(val).strip()
    if not s or s in ("-", ".", "ë¯¸ì •", "n/a", "N/A", "â€”"):
        return False
    # ìˆ«ì 4ìë¦¬ ì´ìƒ + êµ¬ë¶„ì(-./) ìˆìœ¼ë©´ ë‚ ì§œë¡œ ê°„ì£¼
    if any(sep in s for sep in ("-", ".", "/")) and any(c.isdigit() for c in s):
        return True
    # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°(ì—‘ì…€ ì‹œë¦¬ì–¼)
    if s.isdigit() and 10000 <= int(s) <= 1000000:
        return True
    return False


def compute_shot_done_series(df, preferred_date_column=None):
    """ì´¬ì˜ ì™„ë£Œ ì—¬ë¶€(0/1) ì‹œë¦¬ì¦ˆë¥¼ ìƒì„±.

    ë¦¬í„°ì¹­ì™„ë£Œì¼ì— ê°’(ë‚ ì§œ)ì´ ìˆìœ¼ë©´ ê·¸ í–‰ì€ ì´¬ì˜ ì™„ë£Œ(O).
    ë¦¬í„°ì¹­ì™„ë£Œì¼ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì´¬ì˜ì¼ì/í¬í† ì´¬ì˜ì¼ ë“± ë‹¤ë¥¸ ë‚ ì§œ ì»¬ëŸ¼, ì—†ìœ¼ë©´ isShot(0/1) í´ë°±.
    """
    date_col = _find_photo_date_column(df, preferred_name=preferred_date_column)
    if date_col is not None and date_col in df.columns:
        ser = _parse_date_series(df[date_col])
        done = ser.notna().astype(int)
        # íŒŒì‹±ì€ ì‹¤íŒ¨í–ˆì§€ë§Œ ê°’ì´ ë‚ ì§œ í˜•íƒœì¸ ê²½ìš°(ê³µë°±/í˜•ì‹ ì´ìŠˆ) O ì²˜ë¦¬
        if (done == 0).any():
            raw = df[date_col].astype(str).str.strip()
            fallback = raw.apply(_looks_like_date_value).astype(int)
            done = done.where(done == 1, fallback)
        return done

    if "isShot" in df.columns:
        return (pd.to_numeric(df["isShot"], errors="coerce").fillna(0).astype(int) == 1).astype(int)

    return pd.Series([0] * len(df), index=df.index, dtype="int64")

# ----------------------------
# ìŠ¤ëƒ…ìƒ· ì¦ê° ê³„ì‚°
# ----------------------------
def compute_flow_deltas(df):
    if len(df) < 2:
        return None
    this_week = df.iloc[0]
    last_week = df.iloc[1]
    return {
        "ì…ê³ ": this_week["inboundDone"] - last_week["inboundDone"],
        "ì¶œê³ ": this_week["outboundDone"] - last_week["outboundDone"],
        "ì´¬ì˜": this_week["shotDone"] - last_week["shotDone"],
        "ë“±ë¡": this_week["registeredDone"] - last_week["registeredDone"],
        "íŒë§¤ê°œì‹œ": this_week["onSaleDone"] - last_week["onSaleDone"],
    }

# ----------------------------
# ì œëª©
# ----------------------------
st.title("ë¸Œëœë“œ ìƒí’ˆ íë¦„ ëŒ€ì‹œë³´ë“œ")
st.caption("ì…ê³  Â· ì¶œê³  Â· ì´¬ì˜ Â· ë“±ë¡ Â· íŒë§¤ê°œì‹œ í˜„í™©")

# ----------------------------
# Google Sheets ì—°ê²° (Secretsë§Œ ì‚¬ìš©, UI ì—†ìŒ)
# ----------------------------
SPREADSHEET_OPTIONS = {
    "BASE_SPREADSHEET_ID": "BASE",
    "SP_SPREADSHEET_ID": "SP",
    "MI_SPREADSHEET_ID": "MI",
    "CV_SPREADSHEET_ID": "CV",
    "WH_SPREADSHEET_ID": "WH",
    "RM_SPREADSHEET_ID": "RM",
    "EB_SPREADSHEET_ID": "EB",
    "HP_SPREADSHEET_ID": "HP",
    "NK_SPREADSHEET_ID": "NK"
}

def get_spreadsheet_ids_from_secrets():
    ids = {}
    for secret_key, label in SPREADSHEET_OPTIONS.items():
        try:
            val = st.secrets.get(secret_key, "")
            if val and str(val).strip():
                ids[label] = str(val).strip()
        except Exception:
            pass
    return ids

creds_dict = None
try:
    if "gcp_service_account" in st.secrets:
        creds_dict = dict(st.secrets["gcp_service_account"])
    elif "google_service_account" in st.secrets:
        creds_dict = dict(st.secrets["google_service_account"])
except Exception:
    pass
gs_client = get_gsheet_client(creds_dict) if creds_dict else None

spreadsheet_ids = get_spreadsheet_ids_from_secrets()
spreadsheet_title = None
create_spreadsheet_if_missing = False

if not spreadsheet_ids:
    # IDê°€ ì—†ìœ¼ë©´(ì˜µì…˜) ì œëª©ìœ¼ë¡œ ì—´ê¸°/ìƒì„±í•  ìˆ˜ ìˆê²Œ ì§€ì›
    # - AUTO_CREATE_SPREADSHEET=true ì´ê³ 
    # - SPREADSHEET_TITLE(ë˜ëŠ” BASE_SPREADSHEET_TITLE)ê°€ ìˆìœ¼ë©´
    # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ë¥¼ ìƒì„±/ì˜¤í”ˆ í›„ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.
    auto_create = str(st.secrets.get("AUTO_CREATE_SPREADSHEET", "")).strip().lower() in ("1", "true", "yes", "y")
    spreadsheet_title = str(st.secrets.get("SPREADSHEET_TITLE", "")).strip() or str(st.secrets.get("BASE_SPREADSHEET_TITLE", "")).strip()
    if auto_create and spreadsheet_title:
        selected_label = "AUTO"
        spreadsheet_id = None
        create_spreadsheet_if_missing = True
    else:
        st.error("Secretsì— ìŠ¤í”„ë ˆë“œì‹œíŠ¸ IDê°€ ì—†ìŠµë‹ˆë‹¤. BASE_SPREADSHEET_ID ë“±ì„ ì„¤ì •í•˜ê±°ë‚˜, AUTO_CREATE_SPREADSHEET=true ì™€ SPREADSHEET_TITLEì„ ì„¤ì •í•˜ì„¸ìš”.")
        st.stop()
else:
    # ê¸°ë³¸ê°’: Secrets ì²« ë²ˆì§¸ ì‹œíŠ¸, ì²« ì‹œíŠ¸ íƒ­, í—¤ë” 1í–‰
    selected_label = list(spreadsheet_ids.keys())[0]
    spreadsheet_id = spreadsheet_ids[selected_label]
items_sheet_name = ""
# í—¤ë” í–‰(1-based). ê¸°ë³¸ 1 = 1í–‰ì´ ë¨¸ë¦¿ê¸€. 2í–‰ì´ í—¤ë”ì¸ ì‹œíŠ¸ë©´ Secretsì— HEADER_ROW = 2. ìë™ê°ì§€ëŠ” HEADER_ROW = 0
_header_raw = st.secrets.get("HEADER_ROW")
if _header_raw is None or str(_header_raw).strip() == "":
    header_row = 0  # 1í–‰ì´ í—¤ë” (0-based)
elif str(_header_raw).strip().lower() in ("0", "auto", "ìë™"):
    header_row = -1  # 1~3í–‰ ì¤‘ 'ë¦¬í„°ì¹­' í¬í•¨ëœ í–‰ ìë™ ì„ íƒ
else:
    header_row = int(_header_raw) - 1  # 1-based â†’ 0-based
snapshots_sheet_name = ""

if not gs_client:
    st.info("Streamlit Secretsì— **gcp_service_account** ë˜ëŠ” **google_service_account**ë¥¼ ì„¤ì •í•´ ì£¼ì„¸ìš”.")
    st.stop()

# API 429(Quota exceeded) ì™„í™”: ì‹œíŠ¸ IDë§Œ ìˆì„ ë•Œ 90ì´ˆ ìºì‹œ ì‚¬ìš© (header_row ìë™ê°ì§€(-1)ì¼ ë• ë¯¸ì‚¬ìš©)
use_cache = spreadsheet_id and not create_spreadsheet_if_missing and not spreadsheet_title and (header_row >= 0)
if use_cache:
    items_df = _cached_load_sheet(
        str(spreadsheet_id).strip(),
        items_sheet_name.strip() if items_sheet_name else "",
        int(header_row),
    )
else:
    items_df = load_sheet_as_dataframe(
        gs_client,
        spreadsheet_id,
        sheet_name=items_sheet_name if items_sheet_name.strip() else None,
        header_row=header_row,
        spreadsheet_title=spreadsheet_title,
        create_spreadsheet_if_missing=create_spreadsheet_if_missing,
    )
if items_df is None:
    st.stop()
if len(items_df) == 0:
    st.warning("ì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# í•œê¸€/ë‹¤ë¥¸ ì»¬ëŸ¼ëª…ì„ í•„ìˆ˜ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë§¤í•‘
items_df = apply_column_aliases(items_df)

# ë¸Œëœë“œ: ìŠ¤íƒ€ì¼ì½”ë“œ(Now) ì• 2ìë¦¬ â†’ ë§¤í•‘ í…Œì´ë¸” í•œê¸€ëª…
if "styleCode" in items_df.columns:
    items_df["brand"] = items_df["styleCode"].apply(brand_from_style_code)

# ì‹œíŠ¸ì—ì„œ ì½ì€ ê°’ì€ ë¬¸ìì—´ì´ë¯€ë¡œ ìˆ«ì ì»¬ëŸ¼ ë³€í™˜
# ë¦¬í„°ì¹­ ì™„ë£Œì¼ â†’ isShot, ê³µí™ˆë“±ë¡ì¼ â†’ isRegistered: ë‚ ì§œ ë¬¸ìì—´ì„ 0/1ë¡œ ë³€í™˜ (ë‚ ì§œ ìˆìœ¼ë©´ 1)
# ì‹œíŠ¸ì— ë¯¸ì™„ë£Œì¼ ë•Œ '0' ë„£ëŠ” ê²½ìš°ê°€ ìˆìœ¼ë¯€ë¡œ 0/'0'ì€ ë¬´ì¡°ê±´ 'ë‚ ì§œ ì—†ìŒ'(0)ìœ¼ë¡œ ì²˜ë¦¬. êµ¬ê¸€ ì‹œíŠ¸ ë‚ ì§œ(ì—‘ì…€ ì‹œë¦¬ì–¼)ë„ ì¸ì‹
def _date_cell_to_01(ser):
    s = ser.astype(str).str.strip()
    num = pd.to_numeric(ser, errors="coerce")
    no_date = s.isin(("", "0", "0.0", "-", ".")) | (num == 0)
    parsed = pd.to_datetime(ser, errors="coerce")
    # ìˆ«ìë§Œ ìˆëŠ”ë° 10000~1000000 êµ¬ê°„ì´ë©´ ì—‘ì…€/êµ¬ê¸€ ì‹œíŠ¸ ë‚ ì§œ ì‹œë¦¬ì–¼ â†’ ìœ íš¨í•œ ë‚ ì§œë¡œ ê°„ì£¼
    excel_date = num.notna() & (num > 10000) & (num < 1000000)
    if excel_date.any():
        parsed = parsed.fillna(pd.to_datetime(num[excel_date], unit="D", origin="1899-12-30"))
    return (parsed.notna() & ~no_date).astype(int)

if "isShot" in items_df.columns:
    items_df["isShot"] = _date_cell_to_01(items_df["isShot"])
if "isRegistered" in items_df.columns:
    items_df["isRegistered"] = _date_cell_to_01(items_df["isRegistered"])

numeric_cols = [
    "inboundQty", "outboundQty", "stockQty", "salesQty",
    "isShot", "isRegistered", "isOnSale"
]
for col in numeric_cols:
    if col in items_df.columns:
        items_df[col] = pd.to_numeric(items_df[col], errors="coerce").fillna(0).astype(int)

required_columns = [
    "brand", "yearSeason", "styleCode", "productName",
    "colorCode", "colorName", "sizeCode",
    "inboundQty", "outboundQty", "stockQty", "salesQty",
    "isShot", "isRegistered", "isOnSale"
]

missing = [col for col in required_columns if col not in items_df.columns]
if missing:
    items_df = fill_missing_required_columns(items_df, required_columns)

# ----------------------------
# ì´¬ì˜Â·ë“±ë¡ ì—¬ë¶€: ë¸Œëœë“œë³„ ì‹œíŠ¸(SP/MI/CV/RM/WH)ì—ì„œë§Œ ì½ì–´ì„œ merge. BASEì—ì„œëŠ” ì‚¬ìš© ì•ˆ í•¨.
# ----------------------------
preferred_shot_date_col = (st.secrets.get("SHOT_DATE_COLUMN") or "").strip() or None
shot_date_column = None
items_df["__shot_done"] = 0
if "isRegistered" not in items_df.columns:
    items_df["isRegistered"] = 0

if gs_client and spreadsheet_ids and "styleCode" in items_df.columns and "brand" in items_df.columns:
    shot_reg_parts = []
    for brand_name, sheet_key in BRAND_TO_SHEET.items():
        sid = spreadsheet_ids.get(sheet_key)
        if not sid:
            continue
        try:
            _hr = int(header_row) if header_row >= 0 else 0
            b_df = _cached_load_sheet(
                str(sid).strip(),
                items_sheet_name.strip() if items_sheet_name else "",
                _hr,
            )
            if b_df is None or len(b_df) == 0:
                continue
            b_df.columns = [str(c).strip() for c in b_df.columns]
            sc = "styleCode" if "styleCode" in b_df.columns else ("ìŠ¤íƒ€ì¼ì½”ë“œ" if "ìŠ¤íƒ€ì¼ì½”ë“œ" in b_df.columns else None)
            if not sc:
                continue
            b_df["_styleCode"] = b_df[sc].apply(_normalize_style_code_for_merge)
            b_df["brand"] = brand_name

            shot_col = _find_photo_date_column(b_df, preferred_name=preferred_shot_date_col)
            if shot_col and shot_col in b_df.columns:
                # í´ë¼ë¹„ìŠ¤ëŠ” ì—…ë¡œë“œì™„ë£Œì¼ ê°’ ì¡´ì¬ ì—¬ë¶€ë§Œ ì²´í¬
                if brand_name == "í´ë¼ë¹„ìŠ¤":
                    s = b_df[shot_col].astype(str).str.strip()
                    # ê°’ì´ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ ì´¬ì˜ ì™„ë£Œ
                    b_df["__shot_done"] = (
                        ~s.isin(["", "0", "0.0", "-", ".", "1900-01-00"])
                    ).astype(int)
                else:
                    # ë‹¤ë¥¸ ë¸Œëœë“œëŠ” ê¸°ì¡´ ë‚ ì§œ íŒŒì‹± ë¡œì§ ìœ ì§€
                    b_df["__shot_done"] = _date_cell_to_01(b_df[shot_col])
                if shot_date_column is None:
                    shot_date_column = f"{sheet_key} ì‹œíŠ¸ Â· {shot_col}"
            else:
                b_df["__shot_done"] = 0

            reg_col = _find_registration_date_column(b_df)
            if reg_col and reg_col in b_df.columns:
                b_df["isRegistered"] = _date_cell_to_01(b_df[reg_col])
            else:
                b_df["isRegistered"] = 0

            by_style = b_df.groupby("_styleCode", dropna=False).agg({"__shot_done": "max", "isRegistered": "max"}).reset_index()
            by_style["brand"] = brand_name
            shot_reg_parts.append(by_style[["brand", "_styleCode", "__shot_done", "isRegistered"]])
        except Exception:
            continue

    if shot_reg_parts:
        shot_reg_df = pd.concat(shot_reg_parts, ignore_index=True)
        items_df["_styleCode"] = items_df["styleCode"].apply(_normalize_style_code_for_merge)
        merged = items_df[["_styleCode"]].merge(
            shot_reg_df.drop(columns=["brand"]),
            left_on="_styleCode",
            right_on="_styleCode",
            how="left",
        )
        items_df["__shot_done"] = merged["__shot_done"].fillna(0).astype(int)
        items_df["isRegistered"] = merged["isRegistered"].fillna(0).astype(int)
        items_df.drop(columns=["_styleCode"], inplace=True, errors="ignore")

# ----------------------------
# verdict ìƒì„±
# ----------------------------
items_df["verdict"] = items_df.apply(
    lambda r: get_verdict(
        r["inboundQty"],
        r["outboundQty"],
        r["__shot_done"],
        r["isRegistered"],
        r["isOnSale"],
    ),
    axis=1,
)

# ì—°ë„Â·ì‹œì¦Œ: ìŠ¤íƒ€ì¼ì½”ë“œ 5ë²ˆì§¸(ì—°ë„)Â·6ë²ˆì§¸(ì‹œì¦Œ) ìë¦¬ë¡œ íŒŒì•…. ì˜ˆ: sp23g1fh28 â†’ 2026ë…„, 1ì‹œì¦Œ â†’ 20261 ì‹œì¦Œ ìƒí’ˆ
items_df["_year"] = items_df["styleCode"].apply(year_from_style_code)
_ys_from_style = items_df["styleCode"].apply(lambda x: year_season_from_style_code(x)[0])
if (_ys_from_style != "").any():
    items_df["yearSeason"] = items_df["yearSeason"].astype(str)
    items_df.loc[_ys_from_style != "", "yearSeason"] = _ys_from_style[_ys_from_style != ""]
empty_year = items_df["_year"] == ""
if empty_year.any():
    items_df.loc[empty_year, "_year"] = items_df.loc[empty_year, "yearSeason"].astype(str).str[:4]

# ----------------------------
# í•„í„° ì˜ì—­
# ----------------------------
col1, col2, col3, col4 = st.columns(4)
with col1:
    brand_options = sorted(items_df["brand"].unique())
    default_brand_idx = brand_options.index("ìŠ¤íŒŒì˜¤") if "ìŠ¤íŒŒì˜¤" in brand_options else 0
    brand = st.selectbox("ë¸Œëœë“œ", brand_options, index=default_brand_idx)
with col2:
    year = "2026"  # ì—°ë„ ê³ ì •
    st.selectbox("ì—°ë„", [year], key="year", disabled=True)
with col3:
    season_options = sorted(
        items_df.loc[items_df["_year"] == year, "yearSeason"].unique()
    )
    year_seasons = st.multiselect(
        "ì‹œì¦Œ",
        season_options,
        default=season_options if season_options else [],
        key="season",
    )
with col4:
    search = st.text_input(
        "ìŠ¤íƒ€ì¼ì½”ë“œ ê²€ìƒ‰",
        placeholder="ìŠ¤íƒ€ì¼ì½”ë“œ ë˜ëŠ” íŒì • ìƒíƒœ ê²€ìƒ‰",
    )

if year is not None and year_seasons:
    filtered_df = items_df[
        (items_df["brand"] == brand)
        & (items_df["_year"] == year)
        & (items_df["yearSeason"].isin(year_seasons))
    ].copy()
else:
    filtered_df = items_df[(items_df["brand"] == brand)].copy()
    if year is not None:
        filtered_df = filtered_df[filtered_df["_year"] == year]
    if year_seasons:
        filtered_df = filtered_df[filtered_df["yearSeason"].isin(year_seasons)]

if search:
    filtered_df = filtered_df[
        filtered_df["styleCode"].astype(str).str.contains(search, case=False, na=False)
        | filtered_df["verdict"].str.contains(search, case=False, na=False)
    ]

# ë°œì£¼ ìŠ¤íƒ€ì¼ ìˆ˜(ê³ ìœ  styleCode), ì…ê³ /ì¶œê³  ë“±ì€ ìŠ¤íƒ€ì¼ ìˆ˜ë¡œ ì§‘ê³„
total_n = filtered_df["styleCode"].nunique()
if total_n == 0:
    st.info("ì„ íƒí•œ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# ìŠ¤ëƒ…ìƒ· ì¦ê° (ì¹´ë“œì— í•¨ê»˜ í‘œì‹œìš©)
deltas = None
if snapshots_sheet_name and snapshots_sheet_name.strip():
    snapshots_df = load_sheet_as_dataframe(
        gs_client, spreadsheet_id, sheet_name=snapshots_sheet_name.strip()
    )
    if snapshots_df is not None and len(snapshots_df) >= 2:
        snap_cols = ["inboundDone", "outboundDone", "shotDone", "registeredDone", "onSaleDone"]
        for c in snap_cols:
            if c in snapshots_df.columns:
                snapshots_df[c] = pd.to_numeric(snapshots_df[c], errors="coerce").fillna(0).astype(int)
        deltas = compute_flow_deltas(snapshots_df)

# ----------------------------
# íë¦„ ì§‘ê³„ ì¹´ë“œ (ìŠ¤íƒ€ì¼ ìˆ˜ ê¸°ì¤€: í•´ë‹¹ ë‹¨ê³„ 1ê±´ì´ë¼ë„ ìˆìœ¼ë©´ ìŠ¤íƒ€ì¼ í¬í•¨)
# ----------------------------
flow_types = ["ì…ê³ ", "ì¶œê³ ", "ì´¬ì˜", "ë“±ë¡", "íŒë§¤ê°œì‹œ"]
# íë¦„ë³„ ì¡°ê±´: í•´ë‹¹ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” í–‰ì´ í•˜ë‚˜ë¼ë„ ìˆëŠ” ìŠ¤íƒ€ì¼ ìˆ˜
_flow_conditions = {
    "ì…ê³ ": (filtered_df["inboundQty"] > 0),
    "ì¶œê³ ": (filtered_df["outboundQty"] > 0),
    "ì´¬ì˜": (filtered_df["__shot_done"] == 1),
    "ë“±ë¡": (filtered_df["isRegistered"] == 1),
    "íŒë§¤ê°œì‹œ": (filtered_df["isOnSale"] == 1) | (filtered_df["isRegistered"] == 1),
}
flow_counts = pd.Series({
    flow: filtered_df.loc[cond]["styleCode"].nunique()
    for flow, cond in _flow_conditions.items()
})

if "selected_flow" not in st.session_state:
    st.session_state.selected_flow = flow_types[0]

card_cols = st.columns(len(flow_types) + 1)
for i, flow in enumerate(flow_types):
    count = int(flow_counts.get(flow, 0))
    delta_val = deltas.get(flow, 0) if deltas else None
    delta_str = f"â–²{delta_val}" if (delta_val is not None and delta_val > 0) else (str(delta_val) if delta_val is not None else "")
    with card_cols[i]:
        btn_label = f"{flow}\n{count}/{total_n}"
        if delta_str:
            btn_label += f"  {delta_str}"
        if st.button(btn_label, key=f"flow_btn_{flow}", use_container_width=True):
            st.session_state.selected_flow = flow
        if st.session_state.selected_flow == flow:
            st.caption("âœ“ ì„ íƒë¨")

with card_cols[-1]:
    view_mode = st.radio(
        "ë³´ê¸° ë‹¨ìœ„",
        ["ìŠ¤íƒ€ì¼", "ë‹¨í’ˆ"],
        horizontal=True,
        label_visibility="collapsed",
        key="view_mode",
    )

selected_flow = st.session_state.selected_flow

flow_df = filtered_df.loc[_flow_conditions[selected_flow]].copy()

# ìŠ¤íƒ€ì¼ ë‹¨ìœ„: styleCode ê¸°ì¤€ ì§‘ê³„ (ìˆ˜ëŸ‰ í•©ì‚°, ì´¬ì˜/ë“±ë¡/íŒë§¤ê°œì‹œëŠ” í•˜ë‚˜ë¼ë„ 1ì´ë©´ 1)
if view_mode == "ìŠ¤íƒ€ì¼" and len(flow_df) > 0:
    group_cols = ["brand", "yearSeason", "styleCode"]
    agg_dict = {
        "inboundQty": "sum",
        "outboundQty": "sum",
        "stockQty": "sum",
        "salesQty": "sum",
        "isShot": "max",
        "__shot_done": "max",
        "isRegistered": "max",
        "isOnSale": "max",
    }
    if "productName" in flow_df.columns:
        agg_dict["productName"] = "first"
    if "colorName" in flow_df.columns:
        agg_dict["colorName"] = lambda s: " / ".join(s.dropna().astype(str).unique()[:5])
    flow_df = flow_df.groupby(group_cols, dropna=False).agg(agg_dict).reset_index()

flow_df["verdict"] = selected_flow

# í‘œì‹œìš© ì»¬ëŸ¼: ì´¬ì˜ O/X, ë“±ë¡ O/X, íŒë§¤ ìƒíƒœ
flow_df["_ì´¬ì˜"] = flow_df["__shot_done"].map(lambda x: "O" if int(x) == 1 else "X")
flow_df["_ë“±ë¡"] = flow_df["isRegistered"].map(lambda x: "O" if x == 1 else "X")
flow_df["_íŒë§¤"] = flow_df.apply(
    lambda r: "íŒë§¤ê°œì‹œ" if r["isOnSale"] == 1 else ("ì¶œê³ ì „" if r["outboundQty"] == 0 else "ì¶œê³ "),
    axis=1,
)

# ----------------------------
# ìƒì„¸ í…Œì´ë¸” (NO, ìŠ¤íƒ€ì¼ì½”ë“œ, ìƒí’ˆëª…, ì»¬ëŸ¬, ì…ê³ /ì¶œê³ /ì¬ê³ /íŒë§¤ëŸ‰, ì´¬ì˜, ë“±ë¡, íŒë§¤)
# ----------------------------
st.subheader(f"ìƒì„¸ í˜„í™© Â· {selected_flow}")

display_df = flow_df.copy()
display_df.insert(0, "NO", range(1, len(display_df) + 1))
show_cols = ["NO", "styleCode", "productName", "colorName", "inboundQty", "outboundQty", "stockQty", "salesQty", "_ì´¬ì˜", "_ë“±ë¡", "_íŒë§¤"]
show_cols = [c for c in show_cols if c in display_df.columns]
display_df = display_df[show_cols]
display_df = display_df.rename(columns={
    "styleCode": "ìŠ¤íƒ€ì¼ì½”ë“œ",
    "productName": "ìƒí’ˆëª…",
    "colorName": "ì»¬ëŸ¬",
    "inboundQty": "ì…ê³ ëŸ‰",
    "outboundQty": "ì¶œê³ ëŸ‰",
    "stockQty": "ì¬ê³ ëŸ‰",
    "salesQty": "íŒë§¤ëŸ‰",
    "_ì´¬ì˜": "ì´¬ì˜",
    "_ë“±ë¡": "ë“±ë¡",
    "_íŒë§¤": "íŒë§¤",
})

st.dataframe(display_df, use_container_width=True, hide_index=True)

def to_excel(df):
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        df.to_excel(writer, index=False, sheet_name="ìƒì„¸í˜„í™©")
    return output.getvalue()

excel_data = to_excel(display_df)
st.download_button(
    label="Download",
    data=excel_data,
    file_name=f"ìƒì„¸í˜„í™©_{selected_flow}.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
)

# ----------------------------
# ì´¬ì˜ O/X ì›ì¸ í™•ì¸ (ë””ë²„ê·¸)
# ----------------------------
with st.expander("ğŸ” ì´¬ì˜ ì—´ì´ Xë¡œ ë‚˜ì˜¤ëŠ” ì´ìœ  í™•ì¸"):
    st.caption("íŠ¹ì • ìŠ¤íƒ€ì¼ì½”ë“œê°€ ì´¬ì˜ Oê°€ ì•„ë‹ˆë¼ Xë¡œ ë‚˜ì˜¬ ë•Œ, ì–´ë–¤ ì»¬ëŸ¼Â·ê°’ìœ¼ë¡œ íŒì •í–ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.")
    debug_style = st.text_input("ìŠ¤íƒ€ì¼ì½”ë“œ", value="SPABGA9A51", key="debug_style")
    if shot_date_column:
        st.write(f"**ì´¬ì˜ íŒì •ì— ì‚¬ìš© ì¤‘ì¸ ì»¬ëŸ¼:** `{shot_date_column}` (ì—¬ê¸°ì— ìœ íš¨í•œ ë‚ ì§œê°€ ìˆìœ¼ë©´ O)")
    else:
        st.write("**ì´¬ì˜ íŒì •ì— ì‚¬ìš© ì¤‘ì¸ ì»¬ëŸ¼:** ì—†ìŒ â†’ `isShot`(ì´¬ì˜ì—¬ë¶€) ê°’ìœ¼ë¡œ íŒì • ì¤‘.")
        st.caption("ì‹œíŠ¸ì—ì„œ ì½ì€ ì»¬ëŸ¼ ì´ë¦„ ì¤‘ì— ì´¬ì˜/ë¦¬í„°ì¹­/ì—…ë¡œë“œì™„ë£Œ ë‚ ì§œ ì»¬ëŸ¼(ë¦¬í„°ì¹­ì™„ë£Œì¼ ë˜ëŠ” ì—…ë¡œë“œì™„ë£Œì¼ ë“±)ì´ ìˆì–´ì•¼ Oë¡œ í‘œì‹œë©ë‹ˆë‹¤. ì•„ë˜ì—ì„œ í•´ë‹¹ ì»¬ëŸ¼ì„ í™•ì¸í•œ ë’¤, ì—†ë‹¤ë©´ **í—¤ë”ê°€ 2í–‰**ì´ë©´ Secretsì— **HEADER_ROW** = 2 ë¥¼ ë„£ê±°ë‚˜, **SHOT_DATE_COLUMN** = ì»¬ëŸ¼ì´ë¦„(ì •í™•íˆ)ìœ¼ë¡œ ì§€ì •í•˜ì„¸ìš”.")
        all_cols = [c for c in items_df.columns if not str(c).startswith("_")]  # __shot_done, _year ì œì™¸
        # 'ë¦¬í„°ì¹­' í¬í•¨ ì»¬ëŸ¼ ì „ì²´ ê²€ìƒ‰ (ì—°ê´€ í›„ë³´ì—ì„œ ë‚´ë¶€ ì»¬ëŸ¼ ì œì™¸)
        date_like = [c for c in all_cols if any(k in str(c) for k in ("ì´¬ì˜", "ë¦¬í„°ì¹­", "ì—…ë¡œë“œ", "ë³´ì •", "ì™„ë£Œì¼", "ì¼ì", "ë‚ ì§œ", "date", "retouch")) and "shot_done" not in str(c).lower()]
        if date_like:
            st.write("**ë¦¬í„°ì¹­/ì´¬ì˜ ê´€ë ¨ ì»¬ëŸ¼ (ì „ì²´):**", ", ".join(f"`{c}`" for c in date_like))
        else:
            st.warning("'ë¦¬í„°ì¹­' ë˜ëŠ” 'ì´¬ì˜'ì´ ë“¤ì–´ê°„ ì»¬ëŸ¼ì´ ì‹œíŠ¸ì—ì„œ ì½ì€ ëª©ë¡ì— ì—†ìŠµë‹ˆë‹¤. â†’ ì‹œíŠ¸ **2í–‰ì´ í—¤ë”**ë¼ë©´ Secretsì— **HEADER_ROW** = 2 ë¥¼ ë„£ì–´ ë³´ì„¸ìš”.")
        st.write("**ì „ì²´ ì»¬ëŸ¼ (ì¼ë¶€):**", ", ".join(f"`{c}`" for c in all_cols[:35]) + (" â€¦" if len(all_cols) > 35 else ""))
    if debug_style and "styleCode" in items_df.columns:
        rows = items_df[items_df["styleCode"].astype(str).str.strip() == str(debug_style).strip()]
        if len(rows) == 0:
            st.warning(f"ìŠ¤íƒ€ì¼ì½”ë“œ '{debug_style}'ì— í•´ë‹¹í•˜ëŠ” í–‰ì´ ì—†ìŠµë‹ˆë‹¤. (í•„í„° ì¡°ê±´ì´ë‚˜ ì‹œíŠ¸ ë°ì´í„° í™•ì¸)")
        else:
            cols_show = ["styleCode", "__shot_done"]
            if shot_date_column and shot_date_column in items_df.columns:
                cols_show.insert(1, shot_date_column)
            cols_show = [c for c in cols_show if c in rows.columns]
            debug_df = rows[cols_show].copy()
            debug_df["ì´¬ì˜ í‘œì‹œ"] = debug_df["__shot_done"].map(lambda x: "O" if int(x) == 1 else "X")
            st.dataframe(debug_df, use_container_width=True, hide_index=True)
            st.caption("ìœ„ í‘œì—ì„œ **ì´¬ì˜ í‘œì‹œê°€ X**ì¸ ì´ìœ : í•´ë‹¹ í–‰ì˜ ë‚ ì§œ ì»¬ëŸ¼ ê°’ì´ ë¹„ì–´ ìˆê±°ë‚˜, ë‚ ì§œë¡œ ì¸ì‹ë˜ì§€ ì•Šì•˜ê±°ë‚˜, 'ë‚ ì§œì²˜ëŸ¼ ë³´ì´ëŠ” ê°’' ì¡°ê±´ì— ë§ì§€ ì•ŠìŒ.")
